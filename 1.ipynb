{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Data Preprocessing\n",
    "\n",
    "This section of the code fetches the CIFAR-10 dataset using the torchvision library and applies a series of transformations to preprocess the data. Here's a breakdown of the preprocessing steps:\n",
    "\n",
    "1. Data Fetching:\n",
    "\n",
    "- The CIFAR-10 dataset is downloaded and loaded using `torchvision.datasets.CIFAR10`.\n",
    "\n",
    "2. Data Transformations:\n",
    "\n",
    "- `ToTensor`: Converts images to PyTorch tensors\n",
    "- `Normalize`: Normalizes the pixel values of each image. The pixel values are scaled to a range of [-1, 1] by subtracting the mean (0.5, 0.5, 0.5) and dividing by the standard deviation (0.5, 0.5, 0.5) for each color channel (RGB).\n",
    "\n",
    "3. Dataset Splitting:\n",
    "\n",
    "- The dataset is split into three subsets: training, validation, and testing.\n",
    "- The proportions are set as 80% for training, 10% for validation, and 10% for testing.\n",
    "- The `torch.utils.data.random_split` function is used for splitting.\n",
    "\n",
    "4. Data Loaders:\n",
    "\n",
    "- `DataLoader`: Wraps the datasets into iterable loaders, allowing batches of data to be efficiently fetched during training and evaluation.\n",
    "- Parameters:\n",
    "  - `batch_size=64`: The data is processed in mini-batches of 64 images to optimize memory usage and computational efficiency.\n",
    "  - `shuffle=True` (for training): Randomly shuffles the training data to reduce model bias.\n",
    "  - `shuffle=False` (for validation and testing): Maintains the order for consistent evaluation.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "{'images': torch.Size([64, 3, 32, 32]), 'labels': torch.Size([64])}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_data, val_data, test_data = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "\n",
    "print({'images': images.shape, 'labels': labels.shape})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: MLP Model Architecture\n",
    "\n",
    "This section defines, trains, and evaluates a simple Multi-Layer Perceptron (MLP) model for classifying CIFAR-10 images.\n",
    "\n",
    "1. **Model Definition**:\n",
    "   - The `MLPClassifier` class defines the architecture:\n",
    "     - Three fully connected layers: \n",
    "       - `fc1`: Input layer maps 3 * 32 * 32 (32 x 32 images with 3 color channels) = 3072 pixels to 512 neurons.\n",
    "       - `fc2`: Hidden layer with 128 neurons.\n",
    "       - `fc3`: Output layer with 10 neurons (for the 10 classes).\n",
    "     - ReLU activation is used after each layer, except the last one.\n",
    "\n",
    "2. **Loss and Optimizer**:\n",
    "   - Loss: `CrossEntropyLoss`, suitable for multi-class classification.\n",
    "   - Optimizer: `Adam` optimizer with a learning rate of 0.001.\n",
    "\n",
    "3. **Training Loop**:\n",
    "   - The model is trained for 25 epochs.\n",
    "   - Steps:\n",
    "     - Set the model to training mode (`model.train()`).\n",
    "     - Loop through batches of images and labels from `train_loader`.\n",
    "     - Compute predictions, loss, and gradients, and update weights.\n",
    "     - Track the running loss for monitoring.\n",
    "\n",
    "4. **Validation**:\n",
    "   - After training, the model is evaluated on the validation set (`model.eval()`).\n",
    "   - Steps:\n",
    "     - Loop through batches from `val_loader` without gradient computation (`torch.no_grad()`).\n",
    "     - Compute predictions and compare them with ground-truth labels.\n",
    "     - Calculate and print the accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss: 1.6668522901535034\n",
      "Epoch 2, loss: 1.4576457426071168\n",
      "Epoch 3, loss: 1.347080595779419\n",
      "Epoch 4, loss: 1.2577714442253112\n",
      "Epoch 5, loss: 1.1718513425827026\n",
      "Epoch 6, loss: 1.0966192721366883\n",
      "Epoch 7, loss: 1.0276023571014403\n",
      "Epoch 8, loss: 0.9522481573104858\n",
      "Epoch 9, loss: 0.8845983141899109\n",
      "Epoch 10, loss: 0.8137466468334198\n",
      "Epoch 11, loss: 0.7572565513610839\n",
      "Epoch 12, loss: 0.6979521831512451\n",
      "Epoch 13, loss: 0.6411679132461547\n",
      "Epoch 14, loss: 0.5935547897815704\n",
      "Epoch 15, loss: 0.5548017520189286\n",
      "Epoch 16, loss: 0.5271416719198226\n",
      "Epoch 17, loss: 0.48400299334526065\n",
      "Epoch 18, loss: 0.441524991774559\n",
      "Epoch 19, loss: 0.42579258465766906\n",
      "Epoch 20, loss: 0.40573597185611726\n",
      "Epoch 21, loss: 0.3638289365530014\n",
      "Epoch 22, loss: 0.36291205077171323\n",
      "Epoch 23, loss: 0.3441690725684166\n",
      "Epoch 24, loss: 0.3174429668903351\n",
      "Epoch 25, loss: 0.31183267146348953\n",
      "Validation accuracy: 50.84\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch import Tensor\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(3*32*32, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "model = MLPClassifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 25\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch {epoch+1}, loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "model.eval()\n",
    "correct, total = 0, 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Validation accuracy: {100 * correct / total}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
